{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Luther"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at Steam data to predict several factors on user rating\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The basics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#Get them web sites\n",
    "import requests\n",
    "\n",
    "#Make sure slenium works\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import os\n",
    "\n",
    "#Start the google driver\n",
    "chromedriver = \"/Applications/chromedriver\"\n",
    "os.environ[\"webdriver.chrome.driver\"] = chromedriver\n",
    "\n",
    "#make sure to get a consistent table\n",
    "import pickle\n",
    "#need to pick apart strings\n",
    "import re\n",
    "import patsy\n",
    "\n",
    "#needed for graphs\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#For running regressions\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#Sklearn tools\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib\n",
    "matplotlib.style.use('fivethirtyeight') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selenium is used to scrape data from steamspy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chrome driver is used to load Steamspy\n",
    "driver = webdriver.Chrome(chromedriver)\n",
    "driver.get('https://steamspy.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrapes four pages of steamspy trending games for tables\n",
    "#Data is scrapped on 4/21/2018\n",
    "f = []\n",
    "for i in range(4):\n",
    "    i = driver.find_element_by_id('trendinggames')\n",
    "    my_df = pd.read_html(driver.page_source)[0]\n",
    "    i = i.text\n",
    "    i = i.splitlines()\n",
    "    i = i[5:]\n",
    "    f.append(my_df)\n",
    "    site = driver.find_element_by_xpath('//*[@id=\"trendinggames_next\"]/a')\n",
    "    site.click()\n",
    "    time.sleep(1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sanity check\n",
    "pd.read_html(driver.page_source)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stacks the data and corrects the index issues\n",
    "games_data = pd.concat(f)\n",
    "games_data = games_data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickles the data for later\n",
    "games_data.to_pickle('/Users/NickThomas/Project_Luther/data/games_data.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running EDA on the pickled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle sucessfully loaded\n",
    "with open('/Users/NickThomas/Project_Luther/data/games_data.pkl', 'rb') as pickle_file:\n",
    "        games_data_loaded = pickle.load(pickle_file)\n",
    "games_data_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# provides basic info on the dataframe\n",
    "games_data_loaded.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The value counts shows a high number of missing values for the user rating in the steam spy table\n",
    "games_data_loaded['Score rank(Userscore / Metascore)'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional data is gathered from Steam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the complexity of the steam website and the fact that the data frame has 100 cases, searches for games were conducted manually while code was used to scrape each steam entry. Pages were scrapped on 4/22/2018. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A games list is created for reference when making searches\n",
    "game_list = [games_data_loaded.Game.unique()]\n",
    "game_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chrome driver is loaded with the first entry in the list\n",
    "driver = webdriver.Chrome(chromedriver)\n",
    "driver.get('http://store.steampowered.com/search')\n",
    "search = driver.find_element_by_xpath('//*[@id=\"term\"]')\n",
    "search.click()\n",
    "search.send_keys(\"Friday the 13th: Killer Puzzle\")\n",
    "search.send_keys(Keys.RETURN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blank lists are created for incoming variables\n",
    "list3 = []\n",
    "list6 = []\n",
    "list7 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elements are found by their XPATHs. Regular expresions are used to split a review string\n",
    "#into user reviews as a percentage and the amount of people who leave reviews.\n",
    "#Back up code is created if the game has no downloadable content(DLC)\n",
    "rating = driver.find_element_by_xpath('//*[@id=\"game_highlights\"]/div[1]/div/div[3]/div/div[1]')\n",
    "a = rating.text\n",
    "cost_dlc = driver.find_element_by_xpath('//*[@id=\"dlc_purchase_action\"]/div[1]')\n",
    "c = cost_dlc.text\n",
    "#c = np.nan\n",
    "f = re.compile(r'\\d+\\%')\n",
    "g = re.findall(f, str(a))\n",
    "h = re.compile(r'(?<=the\\s).*(?=\\suser)')\n",
    "j = re.findall(h, str(a))\n",
    "print(a)\n",
    "print(c)\n",
    "print(g)\n",
    "print(j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Slight changes to the code were made depending on the circumstance. For example, c = np.nan is hashed out since I was normally expecting dlc cost. When a game didn't have dlc cost, the nan was put in and I hashed the other two out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information from each page is appended to a list.\n",
    "list3.append(c)\n",
    "list6.append(g)\n",
    "list7.append(j)\n",
    "print(list3)\n",
    "print(list6)\n",
    "print(list7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists are converted to arrays\n",
    "dlc_cost = np.asarray(list3)\n",
    "user_rating = np.asarray(list6)\n",
    "number_of_reviews = np.asarray(list7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A dataframe is created form the arrays\n",
    "form = {'dlc_cost': dlc_cost, 'user_rating': user_rating, 'number_of_reviews': number_of_reviews}\n",
    "add_df = pd.DataFrame(form)\n",
    "add_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The two dataframes are joined together\n",
    "Steam_games_df = games_data_loaded.join(add_df)\n",
    "Steam_games_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In case you need to jump in at this point\n",
    "#quickstart\n",
    "with open('/Users/NickThomas/Project_Luther/data/Steam_games_df.pkl', 'rb') as pickle_file:\n",
    "        Steam_games_df = pickle.load(pickle_file)\n",
    "Steam_games_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Info is provided on the main data frame\n",
    "Steam_games_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Values of nan are replaced with $0 to indicate that the game has no dlc or it was free\n",
    "Steam_games_df['dlc_cost'] = Steam_games_df['dlc_cost'].replace('nan', '$0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Null Values are dropped from the analysis\n",
    "mask = Steam_games_df.user_rating.notnull()\n",
    "Steam_games_df = Steam_games_df[mask]\n",
    "Steam_games_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This gets rid of lists created by scrapping data\n",
    "Steam_games_df.reset_index()\n",
    "for x in range(0,86):\n",
    "    Steam_games_df.user_rating.iloc[x] = ''.join(Steam_games_df.user_rating.iloc[x])\n",
    "for x in range(0,86):\n",
    "    Steam_games_df.number_of_reviews.iloc[x] = ''.join(Steam_games_df.number_of_reviews.iloc[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Takes out the percentage sign in user_rating\n",
    "for x in range(0,86):\n",
    "    Steam_games_df.user_rating.iloc[x] = int(Steam_games_df.user_rating.iloc[x][:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Takes out the $ sign in columns with price\n",
    "Steam_games_df['Price'] = Steam_games_df['Price'].replace('Free', '$0')\n",
    "for x in range(0,86):\n",
    "    Steam_games_df.dlc_cost.iloc[x] = float(Steam_games_df.dlc_cost.iloc[x][1:])\n",
    "for x in range(0,86):\n",
    "    Steam_games_df.Price.iloc[x] = float(Steam_games_df.Price.iloc[x][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converts columns to floats and ints\n",
    "Steam_games_df['Price'] = Steam_games_df.Price.astype(float)\n",
    "Steam_games_df['dlc_cost'] = Steam_games_df.dlc_cost.astype(float)\n",
    "Steam_games_df.number_of_reviews = Steam_games_df.number_of_reviews.str.replace(\",\", \"\")\n",
    "Steam_games_df['number_of_reviews'] = Steam_games_df.number_of_reviews.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converts release date to time series\n",
    "Steam_games_df['Release_date'] = Steam_games_df['Release date']\n",
    "for x in range(0,86):\n",
    "    Steam_games_df['Release_date'].iloc[x] = Steam_games_df['Release_date'].replace('Mar 27, 2018', 'March 27, 2018').iloc[x]\n",
    "    Steam_games_df['Release_date'].iloc[x] = Steam_games_df['Release_date'].replace('Mar 26, 2018', 'March 26, 2018').iloc[x]\n",
    "    Steam_games_df['Release_date'].iloc[x] = Steam_games_df['Release_date'].replace('Mar 28, 2018', 'March 28, 2018').iloc[x]\n",
    "    Steam_games_df['Release_date'].iloc[x] = Steam_games_df['Release_date'].replace('Mar 23, 2018', 'March 23, 2018').iloc[x]\n",
    "    Steam_games_df['Release_date'].iloc[x] = Steam_games_df['Release_date'].replace('Mar 30, 2018', 'March 30, 2018').iloc[x]\n",
    "    Steam_games_df['Release_date'].iloc[x] = Steam_games_df['Release_date'].replace('Mar 22, 2018', 'March 22, 2018').iloc[x]\n",
    "    Steam_games_df['Release_date'].iloc[x] = Steam_games_df['Release_date'].replace('Mar 13, 2018', 'March 13, 2018').iloc[x]\n",
    "    Steam_games_df['Release_date'].iloc[x] = Steam_games_df['Release_date'].replace('Mar 20, 2018', 'March 20, 2018').iloc[x]\n",
    "    Steam_games_df['Release_date'].iloc[x] = Steam_games_df['Release_date'].replace('Mar 9, 2018', 'March 9, 2018').iloc[x]\n",
    "    Steam_games_df['Release_date'].iloc[x] = Steam_games_df['Release_date'].replace('Mar 29, 2018', 'March 29, 2018').iloc[x]\n",
    "    Steam_games_df['Release_date'].iloc[x] = Steam_games_df['Release_date'].replace('Mar 21, 2018', 'March 21, 2018').iloc[x]\n",
    "    Steam_games_df['Release_date'].iloc[x] = Steam_games_df['Release_date'].replace('Mar 19, 2018', 'March 19, 2018').iloc[x]\n",
    "    Steam_games_df['Release_date'].iloc[x] = Steam_games_df['Release_date'].replace('Mar 15, 2018', 'March 15, 2018').iloc[x]\n",
    "    Steam_games_df['Release_date'].iloc[x] = Steam_games_df['Release_date'].replace('Mar 14, 2018', 'March 14, 2018').iloc[x]\n",
    "    Steam_games_df['Release_date'].iloc[x] = Steam_games_df['Release_date'].replace('Mar 12, 2018', 'March 12, 2018').iloc[x]\n",
    "    Steam_games_df['Release_date'].iloc[x] = Steam_games_df['Release_date'].replace('Mar 25, 2018', 'March 25, 2018').iloc[x]\n",
    "    Steam_games_df['Release_date'].iloc[x] = Steam_games_df['Release_date'].replace('Mar 8, 2018', 'March 8, 2018').iloc[x]\n",
    "for x in range(0,86):\n",
    "    Steam_games_df['Release_date'].iloc[x] = Steam_games_df['Release_date'].replace('Apr 12, 2018', 'April 12, 2018').iloc[x]\n",
    "    Steam_games_df['Release_date'].iloc[x] = Steam_games_df['Release_date'].replace('Apr 10, 2018', 'April 10, 2018').iloc[x]\n",
    "    Steam_games_df['Release_date'].iloc[x] = Steam_games_df['Release_date'].replace('Apr 6, 2018', 'April 6, 2018').iloc[x]\n",
    "    Steam_games_df['Release_date'].iloc[x] = Steam_games_df['Release_date'].replace('Apr 19, 2018', 'April 19, 2018').iloc[x]\n",
    "    Steam_games_df['Release_date'].iloc[x] = Steam_games_df['Release_date'].replace('Apr 3, 2018', 'April 3, 2018').iloc[x]\n",
    "    Steam_games_df['Release_date'].iloc[x] = Steam_games_df['Release_date'].replace('Apr 9, 2018', 'April 9, 2018').iloc[x]\n",
    "    Steam_games_df['Release_date'].iloc[x] = Steam_games_df['Release_date'].replace('Apr 11, 2018', 'April 11, 2018').iloc[x]\n",
    "    Steam_games_df['Release_date'].iloc[x] = Steam_games_df['Release_date'].replace('Apr 5, 2018', 'April 5, 2018').iloc[x]\n",
    "    Steam_games_df['Release_date'].iloc[x] = Steam_games_df['Release_date'].replace('Apr 18, 2018', 'April 18, 2018').iloc[x]\n",
    "    Steam_games_df['Release_date'].iloc[x] = Steam_games_df['Release_date'].replace('Apr 13, 2018', 'April 13, 2018').iloc[x]\n",
    "    Steam_games_df['Release_date'].iloc[x] = Steam_games_df['Release_date'].replace('Apr 16, 2018', 'April 16, 2018').iloc[x]\n",
    "    Steam_games_df['Release_date'].iloc[x] = Steam_games_df['Release_date'].replace('Apr 14, 2018', 'April 14, 2018').iloc[x]\n",
    "    Steam_games_df['Release_date'].iloc[x] = Steam_games_df['Release_date'].replace('Apr 2, 2018', 'April 2, 2018').iloc[x]\n",
    "    Steam_games_df['Release_date'].iloc[x] = Steam_games_df['Release_date'].replace('Apr 7, 2018', 'April 7, 2018').iloc[x]\n",
    "    Steam_games_df['Release_date'].iloc[x] = Steam_games_df['Release_date'].replace('Apr 4, 2018', 'April 4, 2018').iloc[x]\n",
    "Steam_games_df['Release_date'] = pd.to_datetime(Steam_games_df.Release_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates dummy variables for category\n",
    "Owner_dummy2 = patsy.dmatrix('Owners',data=Steam_games_df,return_type='dataframe')\n",
    "Owner_dummy2.columns = column_names\n",
    "Steam_games_dumb_df = Steam_games_df.join(Owner_dummy2)\n",
    "Steam_games_dumb_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deletes unnecessary columns in the dataframe\n",
    "delete = [\"index\", \"Score rank(Userscore / Metascore\", \"#\", \"Release date\"]\n",
    "Steam_games_dumb_df = Steam_games_dumb_df.drop(columns=[\"index\", \"Score rank(Userscore / Metascore)\", \"#\", \"Release date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assigns the owners column as a categorical variable\n",
    "Steam_games_dumb_df['Owners'] = Steam_games_dumb_df.Owners.astype('category').cat.codes\n",
    "Steam_games_dumb_df.assign(Owners=Steam_games_dumb_df.Owners.astype('category').cat.codes).corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I decided not to chase outliers as I was given advice that in sales data outliers can be important. When looking at variables such as user rating I also wanted to have some idea for where games hit low ratings even if there are not that many of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building my model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prints correlation table of the variables\n",
    "Steam_games_dumb_df.corr()['user_rating'].plot.barh(color='red', edgecolor='black')\n",
    "print(Steam_games_dumb_df.corr()['user_rating'].sort_values())\n",
    "plt.xlabel(\"Correlation\")\n",
    "plt.title(\"Correlations Table\")\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a test-train split\n",
    "x_list = ['Price', 'Owners']\n",
    "X = Steam_games_dumb_df[x_list]\n",
    "y = Steam_games_dumb_df.user_rating\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run a grid search with lasso regression\n",
    "model = Lasso(max_iter=5000)\n",
    "parameters = {'alpha': [1e-5,1e-3,1e-1,1], 'fit_intercept': [True,False]}\n",
    "grid = GridSearchCV(model,parameters, cv=5, scoring='neg_mean_absolute_error', n_jobs=1)\n",
    "grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get a look at the predicted and residual values\n",
    "best_lasso = grid.best_estimator_\n",
    "lasso_pred = best_lasso.predict(X_test)\n",
    "for true,pred in zip(y_test[:20], lasso_pred[:20]):\n",
    "    resid = true - pred\n",
    "    print(\"pred, resid:\", str(pred) + \", \"+ str(resid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at the parameters\n",
    "print(grid.best_params_, grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running a Lasso regression\n",
    "lr2 = Lasso(alpha = .00001)\n",
    "lr2.fit(X_train, y_train)\n",
    "score2 = lr2.score(X_test, y_test)\n",
    "print(\"Lasso Regression: \", score2)\n",
    "print(\"Coef:\", lr2.coef_)\n",
    "y_pred = lr2.predict(X_test)\n",
    "print(\"MSE test:\", mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a plot of actual versus predicted values\n",
    "plt.scatter(y_pred, y_test)\n",
    "plt.axhline(y=0, color='k')\n",
    "plt.plot([55,80],[0,100], 'k--')\n",
    "plt.grid()\n",
    "plt.xlabel(\"Predicted User Rating\")\n",
    "plt.ylabel(\"Actual User Rating\")\n",
    "plt.title(\"Actual vs Predicted Values\")\n",
    "plt.show\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the residuals\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.scatter(y_pred, y_pred - y_test, c='blue', alpha=0.1, s=100, label='(Testing Residuals)')\n",
    "\n",
    "plt.title(\"Residual Plot\")\n",
    "plt.ylim(-10,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like this model has no predictive power. I decided to search for more data in hope of finding other features that could possibily predict user rating in a different dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a new model with kaggle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in Kaggle dataset\n",
    "Steam_kaggle = pd.read_csv('/Users/NickThomas/Project_Luther/data/Video_Game_Sales_as_of_Jan_2017.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get info on new dataset\n",
    "Steam_kaggle.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop null values\n",
    "Steam_kaggle['User_Score'] = Steam_kaggle.User_Score.replace('tbd', np.NaN)\n",
    "Steam_kaggle = Steam_kaggle[Steam_kaggle.User_Score.notnull()]\n",
    "Steam_kaggle = Steam_kaggle[Steam_kaggle.Critic_Score.notnull()]\n",
    "Steam_kaggle_nonnull.info()\n",
    "Steam_kaggle_nonull = Steam_kaggle.dropna()\n",
    "Steam_kaggle_nonnull.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert user score to float\n",
    "Steam_kaggle['User_Score'] = Steam_kaggle.User_Score.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a test-train split\n",
    "x_list = ['Critic_Score', 'Critic_Count', 'Year_of_Release', 'Global_Sales']\n",
    "X = Steam_kaggle_nonull[x_list]\n",
    "y = Steam_kaggle_nonull.User_Score\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run a grid search on Lassor regression for the parameters\n",
    "model = Lasso(max_iter=5000)\n",
    "parameters = {'alpha': [1e-5,1e-3,1e-1,1], 'fit_intercept': [True,False]}\n",
    "grid = GridSearchCV(model,parameters, cv=5, scoring='neg_mean_absolute_error', n_jobs=1)\n",
    "grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get an idea of predicted values and residuals\n",
    "best_lasso = grid.best_estimator_\n",
    "lasso_pred = best_lasso.predict(X_test)\n",
    "for true,pred in zip(y_test[:20], lasso_pred[:20]):\n",
    "    resid = true - pred\n",
    "    print(\"pred, resid:\", str(pred) + \", \"+ str(resid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters for the Lassor regression\n",
    "print(grid.best_params_, grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running a Lasso regression\n",
    "lr2 = Lasso(alpha = 0.1)\n",
    "lr2.fit(X_train, y_train)\n",
    "score2 = lr2.score(X_test, y_test)\n",
    "print(\"Lasso Regression: \", score2)\n",
    "\n",
    "y_pred = lr2.predict(X_test)\n",
    "print(\"Coef:\", lr2.coef_)\n",
    "print(\"MSE test:\", mean_squared_error(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the predicted and actual values for user rating\n",
    "plt.scatter(y_pred, y_test,alpha=0.1)\n",
    "plt.axhline(y=0, color='k')\n",
    "plt.plot([3,10],[3,10], 'k--')\n",
    "plt.grid()\n",
    "plt.xlabel(\"Predicted User Rating\")\n",
    "plt.ylabel(\"Actual User Rating\")\n",
    "plt.title(\"Actual vs Predicted Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the residuals\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.scatter(y_pred, y_pred - y_test, c='blue', alpha=0.1, s=100, label='(Testing Residuals)')\n",
    "\n",
    "plt.title(\"Residual Plot\")\n",
    "plt.ylim(-10,10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
